{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Feature Extraction Layer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aye-Nyein-Thaw/TensorFlow-Beginner/blob/main/3_Feature_Extraction_Layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GanvOdG3_Xt"
      },
      "source": [
        "# Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0USbdEo3_Xu"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCysLQxS3_Xz"
      },
      "source": [
        "## Sequential Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnObj9i_3_X0",
        "outputId": "5683ae31-1768-4d61-ba5a-894e59c509f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(6, name = 'Dense_0', input_shape = (4,)),\n",
        "    Dense(4, name = 'Dense_1'),\n",
        "    Dense(3, name = 'output')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Dense_0 (Dense)              (None, 6)                 30        \n",
            "_________________________________________________________________\n",
            "Dense_1 (Dense)              (None, 4)                 28        \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 3)                 15        \n",
            "=================================================================\n",
            "Total params: 73\n",
            "Trainable params: 73\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AThdTkMt3_X6"
      },
      "source": [
        "## Freeze 2nd layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adfzTdhE3_X7"
      },
      "source": [
        "model.layers[2].trainable = False\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVT4mS0x3_YA"
      },
      "source": [
        "## Load the TensorFlow Hub Feature Vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBG0d6qW3_YB"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "handle_base = \"mobilenet_v2\"\n",
        "pixels = 224\n",
        "output_features = 1280\n",
        "\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
        "\n",
        "# The output of the module is a batch of feature vectors. \n",
        "# For each input image, the feature vector has size num_features = 1280"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0Fcos0A3_YH"
      },
      "source": [
        "## Feature extraction layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obulYIIL3_YI"
      },
      "source": [
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE, input_shape=IMAGE_SIZE + (3,))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCxrKDY73_YM"
      },
      "source": [
        "model = Sequential([\n",
        "            feature_extractor,\n",
        "            Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNXoRTlk74V-"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ewYBiMQ7yao"
      },
      "source": [
        "splits = ['train[:80%]', 'train[80%:90%]', 'train[90%:]']\n",
        "\n",
        "splits, info = tfds.load('cats_vs_dogs', with_info=True, as_supervised=True, split=splits)\n",
        "\n",
        "(train_examples, validation_examples, test_examples) = splits"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaW6OkXk3_YX"
      },
      "source": [
        "num_examples = info.splits['train'].num_examples\n",
        "num_classes = info.features['label'].num_classes\n",
        "\n",
        "class_names = ['cat', 'dog']\n",
        "\n",
        "def format_image(image, label):\n",
        "    image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n",
        "    return  image, label\n",
        "    \n",
        "BATCH_SIZE =  32\n",
        "\n",
        "train_batches = train_examples.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "test_batches = test_examples.map(format_image).batch(BATCH_SIZE)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XangT2OA3_Yb",
        "outputId": "fef2b835-8b38-473f-bc13-ceb36f1ae944",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=3,\n",
        "                    validation_data=validation_batches)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "582/582 [==============================] - 31s 53ms/step - loss: 0.0572 - accuracy: 0.9811 - val_loss: 0.0382 - val_accuracy: 0.9867\n",
            "Epoch 2/3\n",
            "582/582 [==============================] - 30s 52ms/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 0.0370 - val_accuracy: 0.9867\n",
            "Epoch 3/3\n",
            "582/582 [==============================] - 30s 51ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.0404 - val_accuracy: 0.9888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaRndbtH3_Yg"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "filepath = # your code here\n",
        "test_img = load_img(filepath , target_size = (pixels, pixels))\n",
        "\n",
        "# convert image to array\n",
        "img_arr = img_to_array(test_img)\n",
        "\n",
        "# normalize\n",
        "img_arr = img_arr / 255.0\n",
        "\n",
        "# expand_dimensions\n",
        "img_arr = img_arr[np.newaxis, ...]\n",
        "results = model.predict(img_arr)\n",
        "\n",
        "prediction = class_names[np.argmax(results)]\n",
        "print(prediction)\n",
        "\n",
        "display(test_img)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_ZIeNheSBWF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}